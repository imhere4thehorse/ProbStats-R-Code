---
title: "R Session 6"
author: "Kalie and Rebecca"
date: "2023-04-14"
output: html_document
---

```{r setup, include=FALSE}
library(tidyverse)
knitr::opts_chunk$set(echo = TRUE)
```

## Exercise 1

1. 
```{r}
z <- 1.96
p <- 0.4
q <- 0.6
n <- 300
CoI <- tibble(lb = p - (z * sqrt(p*q/n)),
              ub = p + (z * sqrt(p*q/n)))
CoI
```

2.
```{r}
#find z using alpha
ci_p <- function(p, n, a = 0.05){
  q = 1-p
  lb = p - (abs(qnorm(a/2))* sqrt((p*q)/n))
  ub = p + (abs(qnorm(a/2))* sqrt((p*q)/n))
  c(lb, ub)
}
```

3.
```{r}
ci_p(0.4, 300)
 
```

4. 
```{r}
x <- sum(diamonds$carat > 1)
p1 <- x/sum(diamonds$carat >0)
q1 <- 1 - p1
ci_p <- function(p, q, z, n){
  lb = p - (z * sqrt((p*q)/n))
  ub = p + (z * sqrt((p*q)/n))
  output <- list(lb, ub)
  return(output)
}
ci_p(p1, q1, 1.96, 53940)
```

5.

We are 95% confident that the proportion of diamonds that are bigger than 1 carat is between [.3205, .3284]

6. 
```{r}
set.seed(1234)
```
```{r}
samp <- sample(diamonds$carat, 100, replace = FALSE)
sampdf <- data.frame(samp)
```
```{r}
x <- sum(sampdf > 1)
p1 <- x/sum(sampdf >0)
q1 <- 1 - p1
ci_p <- function(p, q, z, n){
  lb = p - (z * sqrt((p*q)/n))
  ub = p + (z * sqrt((p*q)/n))
  output <- list(lb, ub)
  return(output)
}
ci_p(p1, q1, 1.96, 100)
```

7.

The confidence interval for the 100 data set is wider. This is likely because when using a smaller data set, outliers are likley to have a bigger effect on the Condience Interval. Additionally with larger data sets, we are able to get more precise estimations allowing for a smaller interval.

## Excersise 2
1. Construct a 95% CI for μ  with x⎯⎯⎯=20,s=3,n=30.
```{r}
confidenceInterval <- function(xbar, s, n, t) {
  upperBound <- xbar + t * (s / sqrt(n))
  lowerBound <- xbar - t * (s / sqrt(n))
  return(list(upperBound = upperBound, lowerBound = lowerBound))
}

xbar <- 20
s <- 3
n <- 30
t <- qt(0.025, 29)

result <- confidenceInterval(xbar, s, n, t)
result$upperBound
result$lowerBound 
```
2. Make a function that calculates a CI for one population, μ. Again, think carefully about what arguments you want to include and its possible default value.
```{r}
populationMean <- function(mu, s, n, level=0.95) {
  se <- s / sqrt(n)
  z <- abs(qt((1-level)/2, df = n-1)) * se
  lower_bound <- mu - z
  upper_bound <- mu + z
  return(list(lowerBound = lower_bound, upperBound = upper_bound))
}
```
3. Redo problem 1 using your function.

```{r}
populationMean <- function(mu, s, n, level=0.95) {
  se <- s / sqrt(n)
  z <- abs(qt((1-level)/2, df = n-1)) * se
  lower_bound <- mu - z
  upper_bound <- mu + z
  return(list(lowerBound = lower_bound, upperBound = upper_bound))
}

mu <- 20
s <- 3
n <- 30

result <- populationMean(mu, s, n, level=0.95)
result$upperBound
result$lowerBound
```
4. Based on the diamonds, find a 95% confidence interval for the true average price.

```{r}
library(tidyverse)
data(diamonds)

confidenceInterval <- function(xbar, s, n, t) {
  upperBound <- xbar + t * (s / sqrt(n))
  lowerBound <- xbar - t * (s / sqrt(n))
  return(list(upperBound = upperBound, lowerBound = lowerBound))
}

xbar <- mean(diamonds$price)
s <- sd(diamonds$price)
n <- length(diamonds$price)
t <- qt(0.025, n-1)

result <- confidenceInterval(xbar, s, n, t)
result$upperBound
result$lowerBound 
```
5. Interpret above CI.

We are 95% confident that the proportion of the price of diamonds is between 3899.132 and 3966.467

6. Redo problem 4 with n=100. In other words, construct a 95% CI with randomly sampled 100 data points from the diamonds dataset. Useset.seed(1) before you generate the sample. (Hint: you can either sample from a vector (i.e., diamonds$carat) or data frame (i.e., diamonds). You should already know how to sample from a vector. If you want to sample from the data frame, you can use sample_n from the dplyr or tidyverse package.)

```{r}
set.seed(1)
data(diamonds)


sample_size <- 100
sample_data <- diamonds[sample(nrow(diamonds), sample_size), ]

confidenceInterval <- function(xbar, s, n, t) {
  upperBound <- xbar + t * (s / sqrt(n))
  lowerBound <- xbar - t * (s / sqrt(n))
  return(list(upperBound = upperBound, lowerBound = lowerBound))
}

n <- length(sample_data$price)
xbar <- mean(sample_data$price)
s <- sd(sample_data$price)
t <- qt(0.025, n-1)

result <- confidenceInterval(xbar, s, n, t)
result$upperBound
result$lowerBound 
```
7. Compare two CIs. Which one is wider? Explain.

The confidence interval is wider for the one where n=100 because larger samples allows us to estimate a population proportion more precisely and thus gives us narrower intervals in comparison to smaller samples. Thus, the smaller sample size of n=100 has a wider confidence interval.


## Excersise 3
1. Find the coverage for a 95% CI with n=100 and p=0.5. Repeat M = 1000 times. Use set.seed(123) at the very beginning of your code.

I created a fake data set using binomial distribution. From that, I found the confidence interval using the p-hat and I compared it to p.

```{r}
#Generate fake data set, find confidence interval, see if p is in fake data set
#binomial distribution, find p hat, find confidence interval, proportion of 1 is p-hat
set.seed(123)

ci_p <- function(p_hat, n, a = 0.05){
  q_hat = 1-p_hat
  lb = p_hat - (abs(qnorm(a/2))* sqrt((p_hat*q_hat)/n))
  ub = p_hat + (abs(qnorm(a/2))* sqrt((p_hat*q_hat)/n))
  c(lb, ub)
}

n <- 100
p <- 0.5
M <- 1000

cip <- function(p,n,a=0.05){
  binomDist <- rbinom(n,1,p)
  p_hat <- mean(binomDist)
  ci_p(p,n,a=0.05)
  ci <- ci_p(p_hat, n)
  if(p >= ci[1] & p <= ci[2]) 1 else 0
}

output <- replicate(M, cip(p,n,a=0.05))
mean(output)
```
2. What is the theoretical coverage for the above problem?

95% because we're assuming that we're 95% confident

3. Redo with n=100 and p=0.055. Use set.seed(123).
```{r}
set.seed(123)

ci_p <- function(p_hat, n, a = 0.05){
  q_hat = 1-p_hat
  lb = p_hat - (abs(qnorm(a/2))* sqrt((p_hat*q_hat)/n))
  ub = p_hat + (abs(qnorm(a/2))* sqrt((p_hat*q_hat)/n))
  c(lb, ub)
}

n <- 100
p <- 0.055
q <- 0.945
M <- 1000

cip <- function(p,n,a=0.05){
  binomDist <- rbinom(n,1,p)
  p_hat <- mean(binomDist)
  ci_p(p,n,a=0.05)
  ci <- ci_p(p_hat, n)
  if(p >= ci[1] & p <= ci[2]) 1 else 0
}

output <- replicate(M, cip(p,n,a=0.05))
mean(output)
```
4. Redo with n=10,000 and p=0.00055. Use set.seed(123).
```{r}
set.seed(123)

ci_p <- function(p_hat, n, a = 0.05){
  q_hat = 1-p_hat
  lb = p_hat - (abs(qnorm(a/2))* sqrt((p_hat*q_hat)/n))
  ub = p_hat + (abs(qnorm(a/2))* sqrt((p_hat*q_hat)/n))
  c(lb, ub)
}

n <- 10000
p <- 0.00055
q <- 0.99945
M <- 1000


cip <- function(p,n,a=0.05){
  binomDist <- rbinom(n,1,p)
  p_hat <- mean(binomDist)
  ci_p(p,n,a=0.05)
  ci <- ci_p(p_hat, n)
  if(p >= ci[1] & p <= ci[2]) 1 else 0
}

output <- replicate(M, cip(p,n,a=0.05))
mean(output)
```

5. 

np and nq are satisfied in question 3 and are greater than 5
```{r}
100*0.055
100*(1-0.055)
```

The assumption that np and nq are equal to 5 for the CI equation is not satisfied in 4. np = 0.055 < 0.5.
```{r}
100*.00055
100*(1-0.00055)
```

